{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing - Recipe1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dependency import parent_dir\n",
    "from common.save import make_dir, save_pickle, load_pickle, print_time\n",
    "from common.basics import *\n",
    "\n",
    "import copy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, newdata = load_pickle(filename='/opt/eda/data/pplm_data/data_0210.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually categorize the tags in the dataset.<br>\n",
    "The showcase down below is for the cuisine type translation.(Non-North American vs North American style)<br>\n",
    "If you would like to try out other tasks, you may categorize the original tags accordingly.<br>\n",
    "\n",
    "Note: Data has been cleaned by Helena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "904401it [00:43, 20924.53it/s]\n"
     ]
    }
   ],
   "source": [
    "binary_regional_tag = {'north american':['north-american', 'northeastern-united-states','southern-united-states',\\\n",
    "                                         'midwestern','southern','u . s .', 'ontario','canadian'],\n",
    "                       'non-north american':['south-west-pacific', 'south-american', 'colombian', 'cuban', 'costa-rican', 'guatemalan', 'honduran', 'brazilian', 'ecuadorean',\n",
    "                                  'peruvian', 'argentine', 'chilean', 'venezuelan','mexican','south american','caribbean','african', 'somalian', 'south-african', 'moroccan', 'ethiopian', 'egyptian',\n",
    "                                  'nigerian', 'sudanese', 'congolese', 'libyan', 'angolan','moroccan','hawaiian','british-columbian', \n",
    "                                  'rosh-hashanah', 'jewish-ashkenazi', 'jewish-sephardi','cajun', 'central-american',\n",
    "                                  'polish','finnish','greek','czech','italian','german','dutch',\n",
    "                                  'french','belgian','portuguese','iceland','turkish',\n",
    "                                  'hungarian','irish', 'welsh', 'scottish','uk and ireland',\n",
    "                                  'malaysian','indonesian','vietnamese','thai','cambodian','laotian','filipino',\n",
    "                                  'middle-eastern', 'iraqi', 'pakistani', 'iranian-persian','egyptian','persian'\n",
    "                                  'chinese', 'chinese-new-year', 'beijing', 'korean','japanese',\n",
    "                                  'georgian','russian','bangladeshi','indian','nepalese',\n",
    "                                  'australian', 'polynesian', 'new-zealand', 'australian and new zealander']\n",
    "               }\n",
    "\n",
    "regionZ = [t for category, tag in binary_regional_tag.items() for t in tag]\n",
    "equal = {l: i for i, lst in binary_regional_tag.items() for l in lst}\n",
    "\n",
    "labeled, unlabeled = [], []\n",
    "for i , recipe in tqdm.tqdm(enumerate(data)):\n",
    "    newtags = []\n",
    "    if 'tags' in recipe:\n",
    "        # find the related tags\n",
    "        newtags = [t for t in recipe['tags'] if t.replace(' recipe','') in regionZ]\n",
    "        # renames the synonms\n",
    "        newtags = [equal[t] if t in equal else t for t in newtags]\n",
    "    recipe_ = copy.deepcopy(recipe)\n",
    "    if newtags:\n",
    "        recipe_['tags'] = list(set(newtags))\n",
    "        labeled.append(recipe_)\n",
    "    else:\n",
    "        unlabeled.append(recipe_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Data Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For differnet task, we need to format the data accordingly.<br>\n",
    "\n",
    "To train the discriminator, we need full version of recipe (title, ingredients, instructions, seperated by start and end tags)\n",
    "\n",
    "To generated the prompts for GPT2, we only need:\n",
    "- title, ingredients,start-directions tag\n",
    "- title, directions, start-ingredients tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_lis(ingredient_lis):\n",
    "    #format the ingredients: ingre1$ingre2$ingre3\n",
    "    ori = ''\n",
    "    for i in ingredient_lis:\n",
    "        ori = ori + '$' + i\n",
    "    return ori\n",
    "\n",
    "def give_class(tag_lis, reg_infor='north american'):\n",
    "    target = 0\n",
    "    \n",
    "    if len(tag_lis) == 1:\n",
    "        if tag_lis[0] == reg_infor:\n",
    "            target = 1\n",
    "    else:\n",
    "        target = 2\n",
    "    return target\n",
    "\n",
    "#Here define your format\n",
    "data_df['text'] = '<start-title>' + data_df['title'] +'<end-title>'+'<start-directions>' + data_df['instructions'] + '<end-directions> <start-ingredients>'\n",
    "data_df['target'] = data_df['tags'].apply(lambda x: give_class(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start-title>pork and cheese burgers<end-title><start-directions>combine all ingredients in a bowl and mix well, it is probably easiest to add pork last. form into 6 burgers, squeezing tightly to remove any excess moisture. cook on medium to hot barbecue plate until well done, turning once during cooking.<end-directions> <start-ingredients>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of the formatted text\n",
    "\n",
    "data_df['text'].iloc[2021]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Data for Discriminator Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a binary discriminator, we only take the recipes with one tag (either North American or Non-North American)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start-title>cool n easy creamy watermelon pie<end-title><start-directions>dissolve jello in boiling water. allow to cool to room temp. whisk in cool whip. fold in watermelon. spoon into crust. chill for 2-3 hours or overnight. yum!<end-directions> <start-ingredients>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sub = data_df[data_df['target'] != 2][['target','text']]\n",
    "data_sub['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative:  29665 Positive:  28672\n"
     ]
    }
   ],
   "source": [
    "print(\"Negative: \", data_sub[data_sub['target']==0].target.count(), \"Positive: \", data_sub[data_sub['target']==1].target.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sub.to_csv('/opt/eda/data/pplm_data/discriminator_training/north_american_data.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Data for Other Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Back Translation (North American Recipes --> East Asian Recipes --> North American Recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_na = data_df[data_df['target'] == 1]\n",
    "data_na = data_na[['text']]\n",
    "\n",
    "#Sample 50 prompts for back translation\n",
    "#data_na.iloc[:50].to_csv('/opt/eda/data/pplm_data/back_translation/exp_controllable_ingre/na_selected50.txt', sep='\\t', index=False, header=False)\n",
    "#Back translation groundtruth\n",
    "\n",
    "data_na.iloc[:50].to_csv('/opt/eda/data/pplm_data/back_translation/na_selected50_groundtruth.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Source Data for North American Prevalence Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need full version of north-american recipes\n",
    "\n",
    "na_data = data_df[data_df['target']== 1]\n",
    "#na_data.to_csv('/opt/eda/data/pplm_data/ingredients_eval/source_data_na.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distributed sampling 150 recipes for experiments\n",
    "sample_df = data_df.groupby('target').apply(lambda x: x.sample(n=50))\n",
    "\n",
    "#sample_df[['ingredients','instructions','title','text','target']].to_csv('/opt/eda/data/pplm_data/back_translation/exp_controllable_ingre/random150_groundtruth.txt', sep='\\t', index=False)\n",
    "#sample_df['text'].to_csv('/opt/eda/data/pplm_data/back_translation/exp_controllable_ingre/random150.txt', sep='\\t', index=False, header=False)\n",
    "\n",
    "#Randomly sampling 150 North-american for experiments\n",
    "sample_na = data_df[data_df['target']==1].sample(150)\n",
    "\n",
    "#sample_na[['ingredients','instructions','title','text','target']].to_csv('/opt/eda/data/pplm_data/back_translation/exp_controllable_ingre/na150_groundtruth.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
